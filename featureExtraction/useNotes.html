<!DOCTYPE html>
<html>
<head>
<title>useNotes.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<h1 id="opensmile-and-feature-extraction-notes"><strong>OpenSMILE and Feature Extraction Notes</strong></h1>
<p>Authors: Haard Shah, Deborah Santo</p>
<p><strong>TODOs:</strong></p>
<ul>
<li><em>Add Debbie's notes</em></li>
</ul>
<blockquote>
<p>OpenSMILE toolkit - Open-Source Media Interpretation by Large feature-space Extraction</p>
<ul>
<li>Modular and flexible feature extractor for signal processing and machine learning applications</li>
</ul>
</blockquote>
<blockquote>
<p><em>Open-source licence</em> - for private, research, and educational <strong>NOT commercial</strong></p>
<ul>
<li>BUT requires commercial development license to commercialize</li>
</ul>
</blockquote>
<blockquote>
<p>Installation creates <code>SMILExtract</code> executable in local dir and installation location</p>
</blockquote>
<blockquote>
<p><em>Note: appendix-like terminal printouts at the end</em></p>
</blockquote>
<h2 id="table-of-contents"><strong>Table of contents</strong></h2>
<ul>
<li><a href="#first-run">First Run</a></li>
<li><a href="#comparing-signals">Comparing Signals</a></li>
<li><a href="#config-files">Config Files</a></li>
<li><a href="#appendix">Appendix</a>
<ul>
<li><a href="#all-available-components">All available components</a></li>
<li><a href="#smilextract-help">SMILExtract Help</a></li>
</ul>
</li>
</ul>
<h2 id="first-run"><strong>First Run</strong></h2>
<pre class="hljs"><code><div>(impressionist_py3.6) haardshah~/developement/Impressionist/opensmile-2.3.0$ SMILExtract -C config/demo/demo1_energy.conf -I example-audio/media-interpretation.wav -O speech02.energy.csv
(MSG) [2] <span class="hljs-keyword">in</span> SMILExtract : openSMILE starting!
(MSG) [2] <span class="hljs-keyword">in</span> SMILExtract : config file is: config/demo/demo1_energy.conf
(MSG) [2] <span class="hljs-keyword">in</span> cComponentManager : successfully registered 91 component types.
==&gt; LEVEL <span class="hljs-string">'wave'</span>  +++  Buffersize(frames) = 88201  +++  nReaders = 1
==&gt; LEVEL <span class="hljs-string">'waveframes'</span>  +++  Buffersize(frames) = 3  +++  nReaders = 1
==&gt; LEVEL <span class="hljs-string">'energy'</span>  +++  Buffersize(frames) = 3  +++  nReaders = 1
(MSG) [2] <span class="hljs-keyword">in</span> cComponentManager : successfully finished createInstances
									(4 component instances were finalised, 1 data memories were finalised)
(MSG) [2] <span class="hljs-keyword">in</span> cComponentManager : starting single thread processing loop
(MSG) [2] <span class="hljs-keyword">in</span> cComponentManager : Processing finished! System ran <span class="hljs-keyword">for</span> 526 ticks.
</div></code></pre>
<h2 id="comparing-signals"><strong>Comparing Signals</strong></h2>
<ul>
<li><a href="https://stackoverflow.com/a/20672356">Stackoverflow</a>
<ul>
<li>time doman analysis : how visually similar are signals</li>
<li>frequency or time-frequency analysis : how similar audio signals sound</li>
<li>signal variance : for noise measure</li>
<li>See link ^ for matlab code for the following
<ul>
<li>Similarity in time domain (static): <em>Multiply in place and sum</em>.</li>
<li>Similarity in time domain (with shift): Take <em>fft</em> of each signal, <em>multiply</em>, and <em>ifft</em>. (I believe this equivalent to matlab's xcorr.)</li>
<li>Similarity in frequency domain (static): Take <em>fft</em> of each signal, <em>multiply</em>, and <em>sum</em>.</li>
<li>Similarity in frequency domain (with shift): <em>Multiply the two signals and take fft</em>. This will show if the signals share similar spectral shapes.</li>
<li>Similarity in energy (or power if different lengths): <em>Square the two signals and sum each</em> (and divide by signal length for power). (Since the signals were detrended, this should be <em>signal variance</em>.) Then subtract and take absolute value for a measure of signal variance similarity</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://dsp.stackexchange.com/questions/9491/normalized-square-error-vs-pearson-correlation-as-similarity-measures-of-two-sig/9492#9492">Pearson correlation coefficient</a>
<blockquote>
<p>Summarizing, in general the Pearson correlation coefficient gives you a better idea of the similarity of two signals.</p>
</blockquote>
</li>
<li><a href="https://dsp.stackexchange.com/questions/2556/audio-signal-comparison-for-automatic-singing-evaluation/2559#2559">Audio signal comparison for automatic singing evaluation</a></li>
<li>Further research <a href="https://dsp.stackexchange.com/tags/waveform-similarity/hot">Hot answers <code>waveform-similarity</code></a></li>
</ul>
<h2 id="config-files"><strong>Config files</strong></h2>
<p>Outline:</p>
<ul>
<li><a href="#generate-configs">Generate Configs</a></li>
<li><a href="#section-headers">Section Headers</a></li>
<li><a href="#component-connections">Component Connections</a></li>
<li><a href="#section-24">Section 2.4</a> - Inside OpenSMILE</li>
<li><a href="#241-buffers">2.4.1 Buffers</a></li>
<li><a href="#243-opensmile-terminology">2.4.3 OpenSMILE terminology</a></li>
<li><a href="#section-25-default-feature-sets">Section 2.5 Default feature sets</a></li>
<li><a href="#251-available-options-for-audio-input-for-all-standard-config-files">2.5.1 Available options for audio input for all standard config files</a></li>
<li><a href="#prosodic-features">Prosodic features</a></li>
<li><a href="#chroma-features">Chroma features</a></li>
<li><a href="#what-are-chroma-features?">What are chroma features?</a></li>
<li><a href="#mfcc-features">MFCC features</a></li>
<li><a href="#plp-features">PLP features</a></li>
</ul>
<h3 id="generate-configs"><strong>Generate Configs</strong></h3>
<ul>
<li>Generate config files</li>
</ul>
<pre class="hljs"><code><div>SMILExtract -cfgFileTemplate -configDflt cWaveSource,cFramer,cEnergy,cCsvSink -l 1 2&gt; haardconfigs/mydemo.conf
</div></code></pre>
<h3 id="section-headers"><strong>Section Headers</strong></h3>
<ul>
<li><code>[instanceName:componentName]</code></li>
</ul>
<h3 id="component-connections"><strong>Component Connections</strong></h3>
<ul>
<li>Okay having some difficulty understanding this</li>
<li><strong>How to configure component connections?</strong>
<ul>
<li>assigning memory &quot;levels&quot; to the <em>dataReader</em> and <em>dataWriter</em> by modifying <code>reader.dmLevel</code> and <code>writer.dmLevel</code></li>
<li><em>dataReader</em> and <em>dataWriter</em> in each source, sink, or processing component</li>
<li><mark>Section 2.3</mark>: Basics of how to configure openSMILE</li>
</ul>
</li>
<li>UP NEXT
<ul>
<li><strong>2.5</strong></li>
<li><em>standard baseling feature sets of international research competitions</em></li>
<li>also explains cmdline options that the standard feature set configuration files all provide and that can be used to influence parameters of hte data input and output</li>
<li><strong>4.2 - 4.3</strong>: to explore full potential of openSMILE</li>
<li><em>4.2</em> description of the format</li>
<li><em>4.3</em> detailed function and configuration options of all components</li>
</ul>
</li>
</ul>
<h3 id="section-24"><strong>Section 2.4</strong></h3>
<blockquote>
<p>what is going on inside openSMILE, which components exist besides those which are instantiable and connectable via the configuration files, and to learn more about the terminology used.</p>
</blockquote>
<ul>
<li>OpenSmILE split into 3 phases
<ul>
<li>Pre-config phase
<ul>
<li>cmdline options read and config file parsed</li>
</ul>
</li>
<li>
<h2 id="configuration-phase">Configuration phase</h2>
</li>
<li>Execution phase
<ul>
<li>tick-loop</li>
<li>each component has a <code>tick()</code> method</li>
<li></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="241-buffers"><strong>2.4.1 Buffers</strong></h3>
<pre><code>- buffers: *ring-buffer* or *non-ring buffer*
- if you use non-ring buffers, or if you want to process the full input (e.g. for functionals of the complete input, or mean normalization) use dynamically growing non-ring buffer level (see `cDataWriter` configuration for details)
</code></pre>
<ul>
<li>2.4.2 (not documented yet)
<ul>
<li>look at <code>doc/developer/messages.txt</code></li>
<li><code>smileComponent.hpp</code> source file for structural definition of smile messages</li>
</ul>
</li>
</ul>
<h3 id="243-opensmile-terminology"><strong>2.4.3 OpenSMILE terminology</strong></h3>
<pre><code>- *frames*: are an example sample at a timestamp
	- for a &lt;nFields x nTimestamps&gt; matrix, frames would refer to columns
		- *windows* or *contours* correspond to rows of this matrix
	- for exported data files, matrix is transposed, so *fields* are rows here
		- *windows* or *contours* would be columns here
- *elements* refers to actual elements of frame/vectors
- *field*: group of elements that belong together logically and where all elements have the same name
</code></pre>
<h3 id="section-25-default-feature-sets"><strong>Section 2.5 Default feature sets</strong></h3>
<blockquote>
<p>For common tasks from Music Information Retrieval and Speech Recognition fields we provide some example configuration files in the <code>config/</code> directory</p>
</blockquote>
<ul>
<li>
<h2 id="todo-lookup-first-information-about-the-following-feature-sets"><strong>TODO:</strong> Lookup first information about the following feature sets</h2>
</li>
</ul>
<h3 id="251-available-options-for-audio-input-for-all-standard-config-files"><strong>2.5.1 Available options for audio input for all standard config files</strong></h3>
<p align="center"><img src="images/smile-cmd-args.png" align="center">
<ul>
<li><strong>-frameModeFunctionalsConf</strong> option to include and four most common use-cases:</li>
</ul>
<p align="center"><img src="images/frameMode-include-usecases.png" align="center">
<ul>
<li>
<p><strong>bufferMode</strong> configuration</p>
<ul>
<li><em>imp: buffer size configured must be compatible with the frameMode setting in frameModeFunctionalsConf</em></li>
<li>REVIEW <mark>page 34</mark> again</li>
</ul>
</li>
<li>
<p>Page 35 - <strong>output data formats</strong> for the features pulled out</p>
</li>
</ul>
<h3 id="prosodic-features"><strong>Prosodic features</strong></h3>
<ol>
<li><code>config/prosodyAcf.conf</code> and</li>
<li><code>config/prosodyShs.conf</code></li>
</ol>
<ul>
<li>They extract:
<ul>
<li>fundamental frequency (F0)? -</li>
<li>voicing probability -</li>
<li>loudness contours -</li>
</ul>
</li>
<li><strong>default output</strong> - CSV</li>
<li>Command</li>
</ul>
<pre class="hljs"><code><div>SMILExtract -C config/prosodyShs.conf -I input.wav -O prosody.csv
</div></code></pre>
<ul>
<li><code>1</code> uses <code>cPitchACF</code> component
<ul>
<li>extracts <code>f0</code> via an <em>autocorrelation</em> and <em>cepstrum based method</em></li>
</ul>
</li>
<li><code>2</code> uses <code>cPitchShs</code> component
<ul>
<li>extracts <code>f0</code> via the <em>sub-harmonic sampling algorithm (SHS)</em></li>
</ul>
</li>
</ul>
<h3 id="chroma-features"><strong>Chroma features</strong></h3>
<ul>
<li><code>config/chroma_fft.conf</code></li>
<li>command - <code>SMILExtract -C config/chroma_fft.conf -I input.wav -O chroma.csv</code></li>
<li><strong>output</strong>: single line with 12 comma separated values representing mean Chroma values.</li>
</ul>
<p>--&gt; <mark>Resolve</mark>: prolly not a bad idea to test (question still remains, how to compare?)</p>
<h4 id="what-are-chroma-features">What are chroma features?</h4>
<ul>
<li><em>Chroma features</em>: also <em>pitch class profiles</em> are a powerful tool for analyzing usic whose pitches can be meaningfully categorized (into 12 categories)</li>
<li>they <u>capture harmonic and melodic characteristics</u> of music, while being <em>robust to changes in timbre and instrumentation</em> (do we want this?)
<ul>
<li><em>timbre</em>: perceived sound quality of musical note, sound or tone (<em>we don't want to focus on timbre</em>) - so this makes sense? <em><strong>confirm with debbie</strong></em></li>
<li><em>instrumentation</em>: combination of musical instruments employed in a composition, and properties of those instruments individually.</li>
</ul>
<hr>
<ul>
<li>Do we want to capture <u>harmonic and melodic characteristics</u>? <em><strong>debbie?</strong></em></li>
</ul>
</li>
<li>Another APPLICATION: &quot;chroma features have become de facto standard for tasks such as music alignment and synchronization as well as audio structure analysis.&quot; --&gt; <em>Could we align user's dialogue with actor's dialgue?</em></li>
</ul>
<h3 id="mfcc-features"><strong>MFCC features</strong></h3>
<ul>
<li>MFCC - Mel-frequency cepstral coefficient</li>
</ul>
<p>--&gt; <mark>Resolve</mark>: seems helpful in determining prosodic aspects + might help us learn user's voice (timber) for personalization (more custom feature - DREAM BIG)</p>
<ul>
<li>MFCCs are commonly used as feature in speech recognition systems</li>
<li>MFCCs make up an MFC (Mel-frequency cepstrum)
<ul>
<li><em>Mel-freq cepstrum</em> is a representation of the short-term <u>power spectrum</u> of a sound, based on linear cosine transform of a log power spectrum on a nonlinear <em>mel-scale</em> of frequency
<ul>
<li><em>Mel-scale</em>: perceptual scale of pitches judged by listeners to be equal in distance from one another</li>
</ul>
</li>
<li><em>cepstrum</em> result of taking the inverse Fourier transform (IFT) of the logarithm of estimated <em>spectrum</em> of a signal.
<ul>
<li>&quot;Cepstrum pitch determination is particularly effective because the effects of the voical excitation (pitch) and vocal tract (<em>formants</em>) are additive in the logarithm of the power spectrum and thus clearly separate&quot; (<em>what does this mean? - pitch and formants can be separated from log of power spectrum to detection</em>)</li>
<li><em>formants</em>: each of several prominent bands of frequency that determine the phonetic quality of a vowel</li>
<li>4 different sepstrums (&quot;<u><strong>power sepstrum</strong></u> has applications in analysis of human speech)</li>
</ul>
</li>
<li><em>spectrum</em> &quot;any waveform can be represented by a summation of a (possibly infinite) number of sinusoids, each with a particular amplitude and phase. This representation is referred to as the <em>signal's spectrum</em> (or it's frequency-domain representation)&quot; <a href="https://www.music.mcgill.ca/~gary/307/week1/spectra.html">Signal Spectra</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>The cepstrum is a representation used in homomorphic signal processing, to convert signals combined by convolution (such as a source and filter) into sums of their cepstra, for linear separation. In particular, the <u><em>power cepstrum</em></u> is often used as a feature vector for representing the human voice and musical signals. For these applications, the spectrum is usually first transformed using the mel scale. The result is called the mel-frequency cepstrum or MFC (its coefficients are called mel-frequency cepstral coefficients, or MFCCs). It is used for voice identification, pitch detection and much more. The cepstrum is useful in these applications because the low-frequency periodic excitation from the vocal cords and the formant filtering of the vocal tract, which convolve in the time domain and multiply in the frequency domain, are additive and in different regions in the quefrency domain.</p>
</blockquote>
<ul>
<li><strong>Not noise sensitive</strong> - therefore common to normalize their values in speech recognition systems</li>
</ul>
<h3 id="plp-features"><strong>PLP features</strong></h3>
<ul>
<li>PLP : perceptual linear predictive</li>
<li><a href="plp-paper.pdf">Techniques for speaker-independent automatic-speech recognition</a></li>
</ul>
<blockquote>
<p>PLP analysis is computationally efficient and yields a low-dimentional representation of speech.
These properties are found to be useful in <em>speaker-independent automatic-speech recognition</em>.</p>
</blockquote>
<ul>
<li>PLP and <a href="https://www.vocal.com/perceptual-filtering/">Perceptual filtering</a></li>
<li>Could be used to improve performace of speech recognition and reduce computational load</li>
</ul>
<h2 id="high-level-feature-ideas-thoughts"><strong>High level feature ideas / thoughts</strong></h2>
<ul>
<li>To make this highly interactive
<ul>
<li>the front has to be slick</li>
<li>the video should scrub seemlessly (if animated, it should be smooth)</li>
<li>messaged (feedback about performance or program function messages or directions) should be highly personalized and specific. Not general and useless.</li>
</ul>
</li>
<li>Implement sophisticated failsafe option
<ul>
<li>meaning <em>if user is saying it right but we can't see that</em></li>
<li>display personalized messages for special events with special back-end checking</li>
<li>scenarios
<ul>
<li><em>if user performed well but the scored don't reflect that</em>
<ul>
<li>&quot;don't think the scores judging properly? - report it!&quot; OR under the score, have a button that says, &quot;I actually did well!&quot;</li>
<li><em>back-end</em> maybe check for inconsistency between various different feature similarities before even giving that option. OR always give that option but check for inconsistency among different feature similarities before using the feedback</li>
</ul>
</li>
<li><em>when the scores are good but the user didn't actually do</em>
<ul>
<li>Button &quot;I actually don't think I did that well.&quot;</li>
<li><em>back-end</em> this might mean that more than necessary weight given to a feature that was compared. Readjust the weights.
<ul>
<li><em>If it's a personalized neural net, for this and above scenario, manually or some other way label these to be used for training</em></li>
</ul>
</li>
</ul>
</li>
<li><em>user is happy with scores they're getting</em></li>
<li><em>user's hate the scoring</em>
<ul>
<li>ask for text feedback</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="appendix">Appendix</h1>
<h2 id="all-available-components">All Available Components</h2>
<pre class="hljs"><code><div>$ SMILExtract -L
<span class="hljs-comment"># for specific component help:</span>
$ SMILExtract -H cMyComponentName
</div></code></pre>
<pre class="hljs"><code><div>(MSG) [2] <span class="hljs-keyword">in</span> SMILExtract : openSMILE starting!
(MSG) [2] <span class="hljs-keyword">in</span> SMILExtract : config file is: smile.conf
(MSG) [2] <span class="hljs-keyword">in</span> cComponentManager : successfully registered 91 component types.
==&gt; The following 91 components are currently registered <span class="hljs-keyword">in</span> openSMILE:

 +++ <span class="hljs-string">'cDataMemory'</span> +++
   central data memory component

 +++ <span class="hljs-string">'cDataSelector'</span> +++
   This component copies data from one level to another, thereby selecting frame fields and elements by their element/field name.

 +++ <span class="hljs-string">'cVectorProcessor'</span> +++
   dataProcessor, <span class="hljs-built_in">where</span> each array field is processed individually as a vector

 +++ <span class="hljs-string">'cVectorTransform'</span> +++
   this is a base class <span class="hljs-keyword">for</span> vector transforms <span class="hljs-built_in">which</span> require <span class="hljs-built_in">history</span> data or precomputed data (e.g. cepstral mean subtraction, etc.)

 +++ <span class="hljs-string">'cWindowProcessor'</span> +++
   filter dataProcessor, filters each element <span class="hljs-keyword">in</span> a dataMemory level independently

 +++ <span class="hljs-string">'cWinToVecProcessor'</span> +++
   reads input windows, outputs frame(s)

 +++ <span class="hljs-string">'cVecToWinProcessor'</span> +++
   Base class: reads <span class="hljs-keyword">in</span> frames , outputs windows

 +++ <span class="hljs-string">'cExampleSource'</span> +++
   This is an example of a cDataSource descendant. It writes random data to the data memory. This component is intended as a template <span class="hljs-keyword">for</span> developers.

 +++ <span class="hljs-string">'cExampleSink'</span> +++
   This is an example of a cDataSink descendant. It reads data from the data memory and prints it to the console. This component is intended as a template <span class="hljs-keyword">for</span> developers.

 +++ <span class="hljs-string">'cSimpleMessageSender'</span> +++
   This is an example of a cDataSink descendant. It reads data from the data memory and prints it to the console. This component is intended as a template <span class="hljs-keyword">for</span> developers.

 +++ <span class="hljs-string">'cVectorConcat'</span> +++
   concatenates vectors from multiple levels and copy to another level

 +++ <span class="hljs-string">'cFramer'</span> +++
   This component creates frames from single dimensional input stream. It is possible to specify the frame step and frame size independently, thus allowing <span class="hljs-keyword">for</span> overlapping frames or non continuous frames.

 +++ <span class="hljs-string">'cWindower'</span> +++
   This component applies applies window <span class="hljs-keyword">function</span> to pcm frames.

 +++ <span class="hljs-string">'cVectorOperation'</span> +++
   This component performs elementary operations on vectors (i.e. basically everything that does not require <span class="hljs-built_in">history</span> or context, everything that can be performed on single vectors w/o external data (except <span class="hljs-keyword">for</span> constant parameters, etc.))

 +++ <span class="hljs-string">'cValbasedSelector'</span> +++
   This component copies only those frames from the input to the output that match a certain threshold criterion, i.e. <span class="hljs-built_in">where</span> a specified value N exceeds a certain threshold.

 +++ <span class="hljs-string">'cMaxIndex'</span> +++
   This component computes the indices of the features with the maximum absolute values per frame.

 +++ <span class="hljs-string">'cFullinputMean'</span> +++
   This component performs mean normalizing on a data series. A 2-pass analysis of the data is performed, <span class="hljs-built_in">which</span> makes this component unusable <span class="hljs-keyword">for</span> on-line analysis. In the first pass, no output is produced and the mean value (over time) is computed <span class="hljs-keyword">for</span> each input element. In the second pass the mean vector is subtracted from all input frames, and the result is written to the output dataMemory level. Attention: Due to the 2-pass processing the input level must be large enough to hold the whole data sequence.

 +++ <span class="hljs-string">'cFullturnMean'</span> +++
   This component performs mean normalizing on a data series. A 2-pass analysis of the data is performed, <span class="hljs-built_in">which</span> makes this component unusable <span class="hljs-keyword">for</span> on-line analysis. In the first pass, no output is produced and the mean value (over time) is computed <span class="hljs-keyword">for</span> each input element. In the second pass the mean vector is subtracted from all input frames, and the result is written to the output dataMemory level. Attention: Due to the 2-pass processing the input level must be large enough to hold the whole data sequence.

 +++ <span class="hljs-string">'cWaveSource'</span> +++
   This component reads an uncompressed RIFF (PCM-WAVE) file and saves it as a stream to the data memory. For most feature extraction tasks you will now require a cFramer component.

 +++ <span class="hljs-string">'cArffSource'</span> +++
   This component reads WEKA ARFF files. The full ARFF format is not yet supported, but a simplified form, such as the files generated by the cArffSink component can be parsed and <span class="hljs-built_in">read</span>. This component reads all (and only!!) <span class="hljs-string">'numeric'</span> or <span class="hljs-string">'real'</span> attributes from an ARFF file (WEKA file format) into the specified data memory level. Thereby each instance (i.e. one line <span class="hljs-keyword">in</span> the arff file\<span class="hljs-string">'s data section) corresponds to one frame. The frame period is 0 by default (aperiodic level), use the '</span>period<span class="hljs-string">' option to change this and use a fixed period for each frame/instance. Automatic generation of frame timestamps from a '</span>timestamp<span class="hljs-string">' field in the Arff file is not yet supported.

 +++ '</span>cCsvSource<span class="hljs-string">' +++
   This component reads CSV (Comma seperated value) files. It reads all columns as attributes into the data memory. One line represents one frame. The first line may contain a header with the feature names (see header=yes/no/auto option).

 +++ '</span>cHtkSource<span class="hljs-string">' +++
   This component reads data from binary HTK parameter files.

 +++ '</span>cNullSink<span class="hljs-string">' +++
   This component reads data vectors from the data memory and '</span>destroys<span class="hljs-string">' them, i.e. does not write them anywhere. This component has no configuration options.

 +++ '</span>cCsvSink<span class="hljs-string">' +++
   This component exports data in CSV (comma-separated-value) format used in many spreadsheet applications. As the first line of the CSV file a header line may be printed, which contains a delimiter separated list of field names of the output values.

 +++ '</span>cDatadumpSink<span class="hljs-string">' +++
   This component writes dataMemory data to a raw binary file (e.g. for matlab import). The binary file consits of 32-bit float values representing the data values, concattenated frame by frame along the time axis. The first two float values in the file resemble the file header, an thus indicate the dimension of the matrix (1: size of frames, 2: number of frames in file). The total file size in bytes is thus &lt;size of frames&gt;x&lt;number of frames&gt;x4 + 2.

 +++ '</span>cArffSink<span class="hljs-string">' +++
   This component writes dataMemory data to an ARFF file (WEKA). Depending on your config an instance name field, a frame index, and a frame time field can be added as well as multiple class/target attributes. See the config type documentation for more details.

 +++ '</span>cHtkSink<span class="hljs-string">' +++
   This component writes dataMemory data to a binary HTK parameter file.

 +++ '</span>cWaveSink<span class="hljs-string">' +++
   This component saves data to an uncompressed PCM WAVE file

 +++ '</span>cWaveSinkCut<span class="hljs-string">' +++
   This component writes data to uncompressed PCM WAVE files. Only chunks, based on timings received via smile messages are written to files. The files may have consecutive numbers appended to the file name.

 +++ '</span>cBowProducer<span class="hljs-string">' +++
   This component produces a bag-of-words vector from the keyword spotter result message.

 +++ '</span>cSignalGenerator<span class="hljs-string">' +++
   This component provides a signal source. This source generates various noise types and pre-defined signals and value patterns. See the configuration documentation for a list of currently implemented types.

 +++ '</span>cMonoMixdown<span class="hljs-string">' +++
   This is a simple mixer, which adds multiple channels (elements) to a single channel (element).

 +++ '</span>cTransformFFT<span class="hljs-string">' +++
   This component performs an FFT on a sequence of real values (one frame), the output is the complex domain result of the transform. Use the cFFTmagphase component to compute magnitudes and phases from the complex output.

 +++ '</span>cFFTmagphase<span class="hljs-string">' +++
   This component computes magnitude and phase of each array in the input level (it thereby assumes that the arrays contain complex numbers with real and imaginary parts alternating, as computed by the cTransformFFT component).

 +++ '</span>cAmdf<span class="hljs-string">' +++
   This component computes the Average Magnitude Difference Function (AMDF) for each input frame. Various methods for padding or warping at the border exist.

 +++ '</span>cAcf<span class="hljs-string">' +++
   This component computes the autocorrelation function (ACF) by sqauring a magnitude spectrum and applying an inverse Fast Fourier Transform. This component mus read from a level containing *only* FFT magnitudes in a single field. Use the '</span>cTransformFFT<span class="hljs-string">' and '</span>cFFTmagphase<span class="hljs-string">' components to compute the magnitude spectrum from PCM frames. Computation of the Cepstrum is also supported (this applies a log() function to the magnitude spectra).

 +++ '</span>cPreemphasis<span class="hljs-string">' +++
   This component performs pre- and de-emphasis of speech signals using a 1st order difference equation: y(t) = x(t) - k*x(t-1)  (de-emphasis: y(t) = x(t) + k*x(t-1))

 +++ '</span>cVectorPreemphasis<span class="hljs-string">' +++
   This component performs per frame pre-emphasis without an inter-frame state memory. (This is the way HTK does pre-emphasis). Pre-emphasis: y(t) = x(t) - k*x(t-1) ; de-emphasis : y(t) = x(t) + k*x(t-1)

 +++ '</span>cVectorMVN<span class="hljs-string">' +++
   This component extends the base class cVectorTransform and implements mean/variance normalisation. You can use this component to perform on-line cepstral mean normalisation. See cFullinputMean for off-line cepstral mean normalisation.

 +++ '</span>cTurnDetector<span class="hljs-string">' +++
   Speaker turn detector using data from cVadV1 component or cSemaineSpeakerID1 (adaptive VAD) to determine speaker turns and identify continuous segments of voice activity.

 +++ '</span>cDeltaRegression<span class="hljs-string">' +++
   This component computes delta regression coefficients using the regression equation from the HTK book.

 +++ '</span>cContourSmoother<span class="hljs-string">' +++
   This component smooths data contours by applying a moving average filter of configurable length.

 +++ '</span>cSmileResample<span class="hljs-string">' +++
   This component implements a spectral domain resampling component. Input frames are transferred to the spectral domain, then the spectra are shifted, and a modified DFT is performed to synthesize samples at the new rate.

 +++ '</span>cSpecResample<span class="hljs-string">' +++
   This component implements a spectral domain resampling component. Input frames are complex valued spectral domain data, which will be shifted and scaled by this component, and a modified DFT is performed to synthesize samples at the new rate.

 +++ '</span>cDbA<span class="hljs-string">' +++
   This component performs dbX (dbA,dbB,dbC,...) equal loudness weighting of FFT bin magnitudes. Currently only dbA weighting is implemented.

 +++ '</span>cVadV1<span class="hljs-string">' +++
   A voice activity detector based on Line-Spectral-Frequencies, Mel spectra and energy + smoothing. This component requires input of the following type in the following order: MelSpec;lsf;energy. See vadV1.hpp for an example config!

 +++ '</span>cSpecScale<span class="hljs-string">' +++
   This component performs linear/non-linear axis scaling of FFT magnitude spectra with spline interpolation.

 +++ '</span>cMZcr<span class="hljs-string">' +++
   This component computes time signal properties, zero-corssing rate, mean-crossing rate, dc offset, max/min value, and absolute maximum value of a PCM frame.

 +++ '</span>cEnergy<span class="hljs-string">' +++
   This component computes logarithmic (log) and root-mean-square (rms) signal energy from PCM frames.

 +++ '</span>cIntensity<span class="hljs-string">' +++
   This component computes simplified frame intensity (narrow band approximation). IMPORTANT: It expects UNwindowed raw PCM frames as input!! A Hamming window is internally applied and the resulting signal is squared bevore applying loudness compression, etc.

 +++ '</span>cMelspec<span class="hljs-string">' +++
   This component computes an N-band Mel/Bark/Semitone-frequency spectrum (critical band spectrum) by applying overlapping triangular filters equidistant on the Mel/Bark/Semitone-frequency scale to an FFT magnitude or power spectrum.

 +++ '</span>cMfcc<span class="hljs-string">' +++
   This component computes Mel-frequency cepstral coefficients (MFCC) from a critical band spectrum (see '</span>cMelspec<span class="hljs-string">'). An I-DCT of type-II is used from transformation from the spectral to the cepstral domain. Liftering of cepstral coefficients is supported. HTK compatible values can be computed.

 +++ '</span>cPlp<span class="hljs-string">' +++
   This component computes PLP and RASTA-PLP (currently the RASTA filter is not yet implemented) cepstral coefficients from a critical band spectrum (generated by the cMelspec component, for example).
   The component is capable of performing the following processing steps: 
   1) Take the natural logarithm of the critical band powers (doLog)
   2) RASTA filtering
   3) Computation of auditory spectrum (equal loudness curve and loudness compression)
   4) Inverse of the natural logarithm
   5) Inverse DFT to obtain autocorrelation coefficients
   6) Linear prediction analysis on autocorr. coeff.
   7) Computation of cepstral coefficients from lp coefficients
   8) Cepstral '</span>liftering<span class="hljs-string">'

 +++ '</span>cSpectral<span class="hljs-string">' +++
   This component computes spectral features such as flux, roll-off, centroid, and user defined band energies (rectangular summation of FFT magnitudes), etc.

 +++ '</span>cPitchACF<span class="hljs-string">' +++
   This component computes the fundamental frequency and the probability of voicing via an acf and cepstrum based method. The input must be an acf field and a cepstrum field (both generated by a cAcf component).

 +++ '</span>cPitchSmoother<span class="hljs-string">' +++
   This component performs temporal pitch smoothing. Input: candidates produced by a pitchBase descendant (e.g. cPitchSHS). The voicing cutoff threshold is inherited from the input component, thus this smoother component does not provide its own threshold option.

 +++ '</span>cTonespec<span class="hljs-string">' +++
   This component computes (or rather estimates) a semi-tone spectrum from an FFT magnitude spectrum.

 +++ '</span>cTonefilt<span class="hljs-string">' +++
   This component implements an on-line, sample by sample semi-tone filter bank which can be used as first step for the computation of CHROMA features as a replacement of cTonespec. The filter is based on correlating with a sine wave of the exact target frequency of a semi-tone for each note in the filter-bank.

 +++ '</span>cChroma<span class="hljs-string">' +++
   This component computes CHROMA features from a semi-tone scaled spectrum generated by the '</span>cTonespec<span class="hljs-string">' component.

 +++ '</span>cCens<span class="hljs-string">' +++
   This component computes CENS (energy normalised and smoothed chroma features) from raw Chroma features generated by the '</span>cChroma<span class="hljs-string">' component.

 +++ '</span>cHarmonics<span class="hljs-string">' +++
   This component computes statistics of F0 harmonics. It requires an F0 (Hertz) input field and a linear frequency axis magnitude spectrum as input.

 +++ '</span>cPitchSmootherViterbi<span class="hljs-string">' +++
   Viterbi algorithm to smooth pitch contours and remove octave jumps.

 +++ '</span>cPitchJitter<span class="hljs-string">' +++
   This component computes Voice Quality parameters Jitter (pitch period deviations) and Shimmer (pitch period amplitude deviations). It requires the raw PCM frames and the corresponding fundamental frequency (F0) as inputs.

 +++ '</span>cPitchDirection<span class="hljs-string">' +++
   This component reads pitch data, detects pseudo syllables, and computes pitch direction estimates per syllable. Thereby the classes falling, flat, and rising are distinguished. 
    Required input fields: F0, F0env, and '</span>loudness<span class="hljs-string">' or '</span>RMSenergy<span class="hljs-string">'.

 +++ '</span>cPitchShs<span class="hljs-string">' +++
   This component computes the fundamental frequency via the Sub-Harmonic-Sampling (SHS) method (this is related to the Harmonic Product Spectrum method).

 +++ '</span>cLpc<span class="hljs-string">' +++
   This component computes linear predictive coding (LPC) coefficients from PCM frames. Burg\'</span>s algorithm and the standard ACF/Durbin based method are implemented <span class="hljs-keyword">for</span> LPC coefficient computation. The output of LPC filter coefficients, reflection coefficients, residual signal, and LP spectrum is supported.

 +++ <span class="hljs-string">'cLsp'</span> +++
   This component computes LSP (line spectral pair frequencies, also known as LSF) from LPC coefficients by partial factorisation of the LPC polynomial.

 +++ <span class="hljs-string">'cFormantLpc'</span> +++
   This component computes formant frequencies and bandwidths by solving <span class="hljs-keyword">for</span> the roots of the LPC polynomial. The formant trajectories can and should be smoothed by the cFormantSmoother component.

 +++ <span class="hljs-string">'cFormantSmoother'</span> +++
   This component performs temporal formant smoothing. Input: candidates produced by a formant** component AND(!) - appended - an F0final or voicing field (<span class="hljs-built_in">which</span> is 0 <span class="hljs-keyword">for</span> unvoiced frames and non-zero <span class="hljs-keyword">for</span> voiced frames). Output: Smoothed formant frequency contours.

 +++ <span class="hljs-string">'cFunctionals'</span> +++
   computes functionals from input frames, this component uses various cFunctionalXXXX sub-components, <span class="hljs-built_in">which</span> implement the actual functionality

 +++ <span class="hljs-string">'cLibsvmSink'</span> +++
   This component writes data to a text file <span class="hljs-keyword">in</span> LibSVM feature file format. For the <span class="hljs-string">'on-the-fly'</span> classification component see <span class="hljs-string">'cLibsvmliveSink'</span>.
</div></code></pre>
<h2 id="smilextract-help">SMILExtract Help</h2>
<pre class="hljs"><code><div>$ SMILExtract -h
</div></code></pre>
<pre class="hljs"><code><div> =============================================================== 
   openSMILE version 2.3.0 (Rev. 2014:2043)
   Build date: Feb 12 2019 (UNKNOWN-BUILD-DATE)
   Build branch: <span class="hljs-string">'opensmile-2.3.0'</span>
   (c) 2014-2016 by audEERING GmbH
   All rights reserved. See the file COPYING <span class="hljs-keyword">for</span> license terms.
   Lead author: Florian Eyben
 =============================================================== 
 
Usage: SMILExtract [-option (value)] ...
 
 -h    Show this usage information
 
 -C, -configfile  	 &lt;string&gt;
	 Path to openSMILE config file
	 {{ default = <span class="hljs-string">'smile.conf'</span> }}
 
 -l, -loglevel  	 &lt;<span class="hljs-built_in">integer</span> value&gt;
	 Verbosity level (0-9)
	 {{ default = 2 }}
 
 -t, -nticks  	 &lt;<span class="hljs-built_in">integer</span> value&gt;
	 Number of ticks to process (-1 = infinite) (only works <span class="hljs-keyword">for</span> single thread processing, i.e. nThreads=1)
	 {{ default = -1 }}
 
 -L, -components  	 [boolean 0/1]
	 Show component list
	 {{ default = 0 }}
 
 -H, -configHelp  	 [string]
	 Show documentation of registered config types (on/off/argument) (<span class="hljs-keyword">if</span> an argument is given, show only documentation <span class="hljs-keyword">for</span> config types beginning with the name given <span class="hljs-keyword">in</span> the argument)
	 {{ default = <span class="hljs-string">'(null)'</span> }}
 
 -configDflt      	 [string]
	 Show default config section templates <span class="hljs-keyword">for</span> each config <span class="hljs-built_in">type</span> (on/off/argument) (<span class="hljs-keyword">if</span> an argument is given, show only documentation <span class="hljs-keyword">for</span> config types beginning with the name given <span class="hljs-keyword">in</span> the argument, OR <span class="hljs-keyword">for</span> a list of components <span class="hljs-keyword">in</span> conjunctions with the <span class="hljs-string">'cfgFileTemplate'</span> option enabled)
	 {{ default = <span class="hljs-string">'(null)'</span> }}
 
 -cfgFileTemplate      	 [boolean 0/1]
	 Print a complete template config file <span class="hljs-keyword">for</span> a configuration containing the components specified <span class="hljs-keyword">in</span> a comma separated string as argument to the <span class="hljs-string">'configDflt'</span> option
	 {{ default = 0 }}
 
 -cfgFileDescriptions      	 [boolean 0/1]
	 Include description <span class="hljs-keyword">in</span> config file templates.
	 {{ default = 0 }}
 
 -c, -ccmdHelp  	 [boolean 0/1]
	 Show custom commandline option <span class="hljs-built_in">help</span> (those specified <span class="hljs-keyword">in</span> config file)
	 {{ default = 0 }}
 
 -logfile      	 &lt;string&gt;
	 <span class="hljs-built_in">set</span> <span class="hljs-built_in">log</span> file
	 {{ default = <span class="hljs-string">'smile.log'</span> }}
 
 -nologfile      	 [boolean 0/1]
	 don<span class="hljs-string">'t write to a log file (e.g. on a read-only filesystem)
	 {{ default = 0 }}
 
 -noconsoleoutput      	 [boolean 0/1]
	 don'</span>t output any messages to the console (<span class="hljs-built_in">log</span> file is not affected by this option)
	 {{ default = 0 }}
 
 -appendLogfile      	 [boolean 0/1]
	 append <span class="hljs-built_in">log</span> messages to an existing logfile instead of overwriting the logfile at every start
	 {{ default = 0 }}
</div></code></pre>

</body>
</html>

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion-classifier-nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oeGxHoEWJZEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3b039615-c734-46fb-f8bf-427015a82ceb"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/marcogdepinto/Emotion-Classification-Ravdess.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Emotion-Classification-Ravdess'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/67)   \u001b[K\rremote: Counting objects:   2% (2/67)   \u001b[K\rremote: Counting objects:   4% (3/67)   \u001b[K\rremote: Counting objects:   5% (4/67)   \u001b[K\rremote: Counting objects:   7% (5/67)   \u001b[K\rremote: Counting objects:   8% (6/67)   \u001b[K\rremote: Counting objects:  10% (7/67)   \u001b[K\rremote: Counting objects:  11% (8/67)   \u001b[K\rremote: Counting objects:  13% (9/67)   \u001b[K\rremote: Counting objects:  14% (10/67)   \u001b[K\rremote: Counting objects:  16% (11/67)   \u001b[K\rremote: Counting objects:  17% (12/67)   \u001b[K\rremote: Counting objects:  19% (13/67)   \u001b[K\rremote: Counting objects:  20% (14/67)   \u001b[K\rremote: Counting objects:  22% (15/67)   \u001b[K\rremote: Counting objects:  23% (16/67)   \u001b[K\rremote: Counting objects:  25% (17/67)   \u001b[K\rremote: Counting objects:  26% (18/67)   \u001b[K\rremote: Counting objects:  28% (19/67)   \u001b[K\rremote: Counting objects:  29% (20/67)   \u001b[K\rremote: Counting objects:  31% (21/67)   \u001b[K\rremote: Counting objects:  32% (22/67)   \u001b[K\rremote: Counting objects:  34% (23/67)   \u001b[K\rremote: Counting objects:  35% (24/67)   \u001b[K\rremote: Counting objects:  37% (25/67)   \u001b[K\rremote: Counting objects:  38% (26/67)   \u001b[K\rremote: Counting objects:  40% (27/67)   \u001b[K\rremote: Counting objects:  41% (28/67)   \u001b[K\rremote: Counting objects:  43% (29/67)   \u001b[K\rremote: Counting objects:  44% (30/67)   \u001b[K\rremote: Counting objects:  46% (31/67)   \u001b[K\rremote: Counting objects:  47% (32/67)   \u001b[K\rremote: Counting objects:  49% (33/67)   \u001b[K\rremote: Counting objects:  50% (34/67)   \u001b[K\rremote: Counting objects:  52% (35/67)   \u001b[K\rremote: Counting objects:  53% (36/67)   \u001b[K\rremote: Counting objects:  55% (37/67)   \u001b[K\rremote: Counting objects:  56% (38/67)   \u001b[K\rremote: Counting objects:  58% (39/67)   \u001b[K\rremote: Counting objects:  59% (40/67)   \u001b[K\rremote: Counting objects:  61% (41/67)   \u001b[K\rremote: Counting objects:  62% (42/67)   \u001b[K\rremote: Counting objects:  64% (43/67)   \u001b[K\rremote: Counting objects:  65% (44/67)   \u001b[K\rremote: Counting objects:  67% (45/67)   \u001b[K\rremote: Counting objects:  68% (46/67)   \u001b[K\rremote: Counting objects:  70% (47/67)   \u001b[K\rremote: Counting objects:  71% (48/67)   \u001b[K\rremote: Counting objects:  73% (49/67)   \u001b[K\rremote: Counting objects:  74% (50/67)   \u001b[K\rremote: Counting objects:  76% (51/67)   \u001b[K\rremote: Counting objects:  77% (52/67)   \u001b[K\rremote: Counting objects:  79% (53/67)   \u001b[K\rremote: Counting objects:  80% (54/67)   \u001b[K\rremote: Counting objects:  82% (55/67)   \u001b[K\rremote: Counting objects:  83% (56/67)   \u001b[K\rremote: Counting objects:  85% (57/67)   \u001b[K\rremote: Counting objects:  86% (58/67)   \u001b[K\rremote: Counting objects:  88% (59/67)   \u001b[K\rremote: Counting objects:  89% (60/67)   \u001b[K\rremote: Counting objects:  91% (61/67)   \u001b[K\rremote: Counting objects:  92% (62/67)   \u001b[K\rremote: Counting objects:  94% (63/67)   \u001b[K\rremote: Counting objects:  95% (64/67)   \u001b[K\rremote: Counting objects:  97% (65/67)   \u001b[K\rremote: Counting objects:  98% (66/67)   \u001b[K\rremote: Counting objects: 100% (67/67)   \u001b[K\rremote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 289 (delta 27), reused 0 (delta 0), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (289/289), 4.34 MiB | 16.88 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tea0gZEoCBrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d2532113-bbce-4625-ed4c-b1cdcfe43463"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c0zhMp47EA4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "66f874cb-2a98-48f4-dfdc-3ae88c3ab6c4"
      },
      "cell_type": "code",
      "source": [
        "%cd /gdrive/'My Drive'/'Colab Notebooks'/\n",
        "!ls"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/Colab Notebooks\n",
            "audio_four.wav\t audio_two.wav\t\t      mlpclassifier-test.ipynb\n",
            "audio_one.wav\t emotion-classifier-nn.ipynb  pretending-to-be-happy.wav\n",
            "audio_three.wav  input.energy.csv\t      speech-to-text-0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vhwbAd6wZwc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv /gdrive/'My Drive'/'Colab Notebooks'/pretending-to-be-happy.wav /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWe-co7waRsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82cf947d-e3e3-4783-da55-4cc27e857d15"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0nUhHSIyKnB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!ffmpeg -i /gdrive/'My Drive'/'Colab Notebooks'/opensmile.wav -ab 160k -ac 2 -ar 44100 -vn opensmile.wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfyOzH-0444M",
        "colab_type": "code",
        "outputId": "2ab5b947-3792-4f2f-8ade-0361fc014c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "class livePredictions:\n",
        "\n",
        "    def __init__(self, path, file):\n",
        "\n",
        "        self.path = path\n",
        "        self.file = file\n",
        "\n",
        "    def load_model(self):\n",
        "        '''\n",
        "        I am here to load you model.\n",
        "        :param path: path to your h5 model.\n",
        "        :return: summary of the model with the .summary() function.\n",
        "        '''\n",
        "        self.loaded_model = keras.models.load_model(self.path)\n",
        "        return self.loaded_model.summary()\n",
        "\n",
        "    def makepredictions(self):\n",
        "        '''\n",
        "        I am here to process the files and create your features.\n",
        "        '''\n",
        "        data, sampling_rate = librosa.load(self.file)\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0) \n",
        "        x = np.expand_dims(mfccs, axis=2)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        predictions = self.loaded_model.predict_classes(x)\n",
        "        print( \"Prediction is\", \" \", self.convertclasstoemotion(predictions))\n",
        "\n",
        "    def convertclasstoemotion(self, pred):\n",
        "        '''\n",
        "        I am here to convert the predictions (int) into human readable strings.\n",
        "        '''\n",
        "        self.pred  = pred\n",
        "\n",
        "        if pred == 0:\n",
        "            pred = \"neutral\"\n",
        "            return pred\n",
        "        elif pred == 1:\n",
        "            pred = \"calm\"\n",
        "            return pred\n",
        "        elif pred == 2:\n",
        "            pred = \"happy\"\n",
        "            return pred\n",
        "        elif pred == 3:\n",
        "            pred = \"sad\"\n",
        "            return pred\n",
        "        elif pred == 4:\n",
        "            pred = \"angry\"\n",
        "            return pred\n",
        "        elif pred == 5:\n",
        "            pred = \"fearful\"\n",
        "            return pred\n",
        "        elif pred == 6:\n",
        "            pred = \"disgust\"\n",
        "            return pred\n",
        "        elif pred == 7:\n",
        "            pred = \"surprised\"\n",
        "            return pred\n",
        "\n",
        "# Here you can replace path and file with the path of your model and of the file from the RAVDESS dataset you want to use for the prediction,\n",
        "# Below, I have used a neutral file: the prediction made is neutral.\n",
        "\n",
        "pred = livePredictions(path='Emotion_Voice_Detection_Model.h5',\n",
        "                       file='pretending-to-be-happy.wav')\n",
        "\n",
        "pred.load_model()\n",
        "pred.makepredictions()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 40, 128)           768       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 5, 128)            82048     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 640)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 5128      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 87,944\n",
            "Trainable params: 87,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Prediction is   calm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iAmNKCa46l3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}